<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Chinglish Small Talk</title>
  
  <subtitle>Tech and Personal Blog of Ofey Chan</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://yoursite.com/"/>
  <updated>2019-07-15T08:12:41.224Z</updated>
  <id>http://yoursite.com/</id>
  
  <author>
    <name>Ofey Chan</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Mac Custom</title>
    <link href="http://yoursite.com/2019/07/15/mac-custom/"/>
    <id>http://yoursite.com/2019/07/15/mac-custom/</id>
    <published>2019-07-15T08:09:25.000Z</published>
    <updated>2019-07-15T08:12:41.224Z</updated>
    
    <content type="html"><![CDATA[<p>Mac 电脑整体的设计思路和机甲片里的「特装机」一样——不惜工本，提升某几个方面的性能，不易整备，零件/技能不易通用。</p><a id="more"></a><p>但 Mac 好的是在特化的同时保持了界面友好性，学习成本相当低，比起难以驾驭的「古铁巨人」更像界面友好的「初代高达」——并不需要太多特殊技术也能发挥相当一部分性能，单纯只是造价高昂、不易维护而已。</p><p>特机给一般操纵士来开，当然会有诸多怨言——难以后勤补给、和队友的兼容性差、某些方面因为特殊设计而产生缺陷。同时对特机的特化性能优势，如果抱着一般操纵士的思维，也难以有效利用。</p><p>当然也有「相良宗介」这种量产大神……但是人家嘴上百般嫌弃特机「强弩」，最后还是乖乖一路用「强弩」和「利维坦」打到了破关:) </p><p>特机是设计出来在特殊情境下发挥非凡价值的机械，其能力的发挥需要配得上它的特殊操纵士和合适的场景。一般操纵士开特机会有反效果，是因为他们承受了特机带来的问题，却没能发挥出特机的价值。</p><blockquote><p>Macintosh、出る！</p></blockquote><p>另外HHKB是真的需要一些特殊技巧。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Mac 电脑整体的设计思路和机甲片里的「特装机」一样——不惜工本，提升某几个方面的性能，不易整备，零件/技能不易通用。&lt;/p&gt;
    
    </summary>
    
      <category term="Hardware" scheme="http://yoursite.com/categories/Hardware/"/>
    
      <category term="MacBook" scheme="http://yoursite.com/categories/Hardware/MacBook/"/>
    
    
      <category term="Robot" scheme="http://yoursite.com/tags/Robot/"/>
    
      <category term="lan-chinese" scheme="http://yoursite.com/tags/lan-chinese/"/>
    
      <category term="design" scheme="http://yoursite.com/tags/design/"/>
    
      <category term="productivity" scheme="http://yoursite.com/tags/productivity/"/>
    
  </entry>
  
  <entry>
    <title>Web Scraping Introduction with Scrapy</title>
    <link href="http://yoursite.com/2019/07/12/web-scraping-intro-with-scrapy/"/>
    <id>http://yoursite.com/2019/07/12/web-scraping-intro-with-scrapy/</id>
    <published>2019-07-12T15:27:41.000Z</published>
    <updated>2019-07-12T15:37:52.964Z</updated>
    
    <content type="html"><![CDATA[<p>Resources</p><ul><li><a href="https://www.datacamp.com/community/tutorials/making-web-crawlers-scrapy-python" target="_blank" rel="noopener">Making Web Crawlers Using Scrapy for Python</a></li><li><a href="https://docs.scrapy.org/en/latest/intro/overview.html" target="_blank" rel="noopener">docs of Scrapy</a></li><li><a href="https://github.com/geekan/scrapy-examples/tree/master/doubanbook" target="_blank" rel="noopener">geekan/scrapy-examples</a></li></ul><a id="more"></a><h2 id="Create-a-project"><a href="#Create-a-project" class="headerlink" title="Create a project"></a>Create a project</h2><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">scrapy startproject &lt;names&gt;</span><br></pre></td></tr></table></figure><h2 id="First-spider"><a href="#First-spider" class="headerlink" title="First spider"></a>First spider</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> scrapy</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">QuotesSpider</span><span class="params">(scrapy.Spider)</span>:</span></span><br><span class="line">    name = <span class="string">"quotes"</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">start_requests</span><span class="params">(self)</span>:</span></span><br><span class="line">        urls = [</span><br><span class="line">            <span class="string">'http://quotes.toscrape.com/page/1/'</span>,</span><br><span class="line">            <span class="string">'http://quotes.toscrape.com/page/2/'</span>,</span><br><span class="line">        ]</span><br><span class="line">        <span class="keyword">for</span> url <span class="keyword">in</span> urls:</span><br><span class="line">            <span class="keyword">yield</span> scrapy.Request(url=url, callback=self.parse)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">parse</span><span class="params">(self, response)</span>:</span></span><br><span class="line">        page = response.url.split(<span class="string">"/"</span>)[<span class="number">-2</span>]</span><br><span class="line">        filename = <span class="string">'quotes-%s.html'</span> % page</span><br><span class="line">        <span class="keyword">with</span> open(filename, <span class="string">'wb'</span>) <span class="keyword">as</span> f:</span><br><span class="line">            f.write(response.body)</span><br><span class="line">        self.log(<span class="string">'Saved file %s'</span> % filename)</span><br></pre></td></tr></table></figure><h2 id="Run-spider"><a href="#Run-spider" class="headerlink" title="Run spider"></a>Run spider</h2><p>Go to top level and run:</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">scrapy crawl quotes</span><br></pre></td></tr></table></figure><p>Start url can also define explictly in variable <strong>start_urls</strong>.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> scrapy</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">QuotesSpider</span><span class="params">(scrapy.Spider)</span>:</span></span><br><span class="line">    name = <span class="string">"quotes"</span></span><br><span class="line">    start_urls = [</span><br><span class="line">        <span class="string">'http://quotes.toscrape.com/page/1/'</span>,</span><br><span class="line">        <span class="string">'http://quotes.toscrape.com/page/2/'</span>,</span><br><span class="line">    ]</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">parse</span><span class="params">(self, response)</span>:</span></span><br><span class="line">        page = response.url.split(<span class="string">"/"</span>)[<span class="number">-2</span>]</span><br><span class="line">        filename = <span class="string">'quotes-%s.html'</span> % page</span><br><span class="line">        <span class="keyword">with</span> open(filename, <span class="string">'wb'</span>) <span class="keyword">as</span> f:</span><br><span class="line">            f.write(response.body)</span><br></pre></td></tr></table></figure><h2 id="Extracting-data"><a href="#Extracting-data" class="headerlink" title="Extracting data"></a>Extracting data</h2><p>response.css() method can do this.</p><p>It returns a <strong>Selectlist</strong> object. Can be stripped and queried further.</p><p><strong>Methods</strong></p><ul><li>getall()</li><li>get()</li><li>re(): Extract using regular expressions.</li></ul><p>response.xpath() method is more under-the-hood.</p><p>A example below:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">parse</span><span class="params">(self, response)</span>:</span></span><br><span class="line">    <span class="keyword">for</span> quote <span class="keyword">in</span> response.css(<span class="string">'div.quote'</span>):</span><br><span class="line">        <span class="keyword">yield</span> &#123;</span><br><span class="line">            <span class="string">'text'</span>: quote.css(<span class="string">'span.text::text'</span>).get(),</span><br><span class="line">            <span class="string">'author'</span>: quote.css(<span class="string">'small.author::text'</span>).get(),</span><br><span class="line">            <span class="string">'tags'</span>: quote.css(<span class="string">'div.tags a.tag::text'</span>).getall(),</span><br><span class="line">        &#125;</span><br></pre></td></tr></table></figure><h2 id="Store-the-scraped-data"><a href="#Store-the-scraped-data" class="headerlink" title="Store the scraped data"></a>Store the scraped data</h2><blockquote><p>For historic reasons, Scrapy appends to a given file instead of overwriting its contents. If you run this command twice without removing the file before the second time, you’ll end up with a broken JSON file.</p></blockquote><p>The JSON lines format is easy to append.</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">scrapy crawl quotes -o quotes.json</span><br><span class="line">scrapy crawl quotes -o quotes.jl  <span class="comment"># JSON lines</span></span><br></pre></td></tr></table></figure><p>All formats for <a href="https://docs.scrapy.org/en/latest/topics/feed-exports.html#topics-feed-exports" target="_blank" rel="noopener">Feed exports</a></p><h2 id="Follow-links"><a href="#Follow-links" class="headerlink" title="Follow links"></a>Follow links</h2><p>With attrib[] attribute, or select in the css() method.</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; response.css(<span class="string">'li.next a::attr(href)'</span>).get()</span><br><span class="line"><span class="string">'/page/2/'</span></span><br><span class="line">&gt;&gt;&gt; response.css(<span class="string">'li.next a'</span>).attrib[<span class="string">'href'</span>]</span><br><span class="line"><span class="string">'/page/2'</span></span><br></pre></td></tr></table></figure><p><strong>Recursively follow the “Next Page” link</strong></p><p>Build the full absolute URL with urljoin() method.</p><blockquote><p>What you see here is Scrapy’s mechanism of following links: when you yield a Request in a callback method, Scrapy will schedule that request to be sent and register a callback method to be executed when that request finishes.</p></blockquote><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">def parse(self, response):</span><br><span class="line">    <span class="keyword">for</span> quote <span class="keyword">in</span> response.css(<span class="string">'div.quote'</span>):</span><br><span class="line">        yield &#123;</span><br><span class="line">            <span class="string">'text'</span>: quote.css(<span class="string">'span.text::text'</span>).get(),</span><br><span class="line">            <span class="string">'author'</span>: quote.css(<span class="string">'small.author::text'</span>).get(),</span><br><span class="line">            <span class="string">'tags'</span>: quote.css(<span class="string">'div.tags a.tag::text'</span>).getall(),</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">    next_page = response.css(<span class="string">'li.next a::attr(href)'</span>).get()</span><br><span class="line">    <span class="keyword">if</span> next_page is not None:</span><br><span class="line">        next_page = response.urljoin(next_page)</span><br><span class="line">        yield scrapy.Request(next_page, callback=self.parse)</span><br></pre></td></tr></table></figure><p>response.follow support relative URLs directly. Otherwise you can pass a selector directly(with necessary attributes).</p><p>For &lt;a&gt; method there’s a shortcut: follow their href attribute automatically.</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> next_page is not None:</span><br><span class="line">    yield response.follow(next_page, callback=self.parse)</span><br><span class="line"></span><br><span class="line"><span class="comment"># pass a selector</span></span><br><span class="line"><span class="keyword">for</span> href <span class="keyword">in</span> response.css(<span class="string">'li.next a::attr(href)'</span>):</span><br><span class="line">    yield response.follow(href, callback=self.parse)</span><br><span class="line">    </span><br><span class="line"><span class="comment"># follow &lt;a&gt; elements directly</span></span><br><span class="line"><span class="keyword">for</span> a <span class="keyword">in</span> response.css(<span class="string">'li.next a'</span>):</span><br><span class="line">    yield response.follow(a, callback=self.parse)</span><br></pre></td></tr></table></figure><h2 id="For-Deeper-Scraping"><a href="#For-Deeper-Scraping" class="headerlink" title="For Deeper Scraping"></a>For Deeper Scraping</h2><p>With the callback variable of response.follow() or scrapy.Request() method.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> scrapy</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">AuthorSpider</span><span class="params">(scrapy.Spider)</span>:</span></span><br><span class="line">    name = <span class="string">'author'</span></span><br><span class="line"></span><br><span class="line">    start_urls = [<span class="string">'http://quotes.toscrape.com/'</span>]</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">parse</span><span class="params">(self, response)</span>:</span></span><br><span class="line">        <span class="comment"># follow links to author pages</span></span><br><span class="line">        <span class="keyword">for</span> href <span class="keyword">in</span> response.css(<span class="string">'.author + a::attr(href)'</span>):</span><br><span class="line">            <span class="keyword">yield</span> response.follow(href, self.parse_author)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># follow pagination links</span></span><br><span class="line">        <span class="keyword">for</span> href <span class="keyword">in</span> response.css(<span class="string">'li.next a::attr(href)'</span>):</span><br><span class="line">            <span class="keyword">yield</span> response.follow(href, self.parse)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">parse_author</span><span class="params">(self, response)</span>:</span></span><br><span class="line">        <span class="function"><span class="keyword">def</span> <span class="title">extract_with_css</span><span class="params">(query)</span>:</span></span><br><span class="line">            <span class="keyword">return</span> response.css(query).get(default=<span class="string">''</span>).strip()</span><br><span class="line"></span><br><span class="line">        <span class="keyword">yield</span> &#123;</span><br><span class="line">            <span class="string">'name'</span>: extract_with_css(<span class="string">'h3.author-title::text'</span>),</span><br><span class="line">            <span class="string">'birthdate'</span>: extract_with_css(<span class="string">'.author-born-date::text'</span>),</span><br><span class="line">            <span class="string">'bio'</span>: extract_with_css(<span class="string">'.author-description::text'</span>),</span><br><span class="line">        &#125;</span><br></pre></td></tr></table></figure><p>Q: How can I pass some information of current page to the next page to be parsed?</p><h2 id="Arguments"><a href="#Arguments" class="headerlink" title="Arguments"></a>Arguments</h2><p>Spiders can have <a href="https://docs.scrapy.org/en/latest/topics/spiders.html#spiderargs" target="_blank" rel="noopener">arguments</a>.</p><h2 id="Item-Pipeline"><a href="#Item-Pipeline" class="headerlink" title="Item Pipeline"></a>Item Pipeline</h2><blockquote><p>After an item has been scraped by a spider, it is sent to the Item Pipeline which processes it through several components that are executed sequentially.</p></blockquote><p><a href="https://docs.scrapy.org/en/latest/topics/item-pipeline.html#topics-item-pipeline" target="_blank" rel="noopener">more information</a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Resources&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;https://www.datacamp.com/community/tutorials/making-web-crawlers-scrapy-python&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Making Web Crawlers Using Scrapy for Python&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://docs.scrapy.org/en/latest/intro/overview.html&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;docs of Scrapy&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://github.com/geekan/scrapy-examples/tree/master/doubanbook&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;geekan/scrapy-examples&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
    
    </summary>
    
      <category term="Programming" scheme="http://yoursite.com/categories/Programming/"/>
    
      <category term="Web Crawler" scheme="http://yoursite.com/categories/Programming/Web-Crawler/"/>
    
    
      <category term="python" scheme="http://yoursite.com/tags/python/"/>
    
      <category term="scrapy" scheme="http://yoursite.com/tags/scrapy/"/>
    
      <category term="lan-english" scheme="http://yoursite.com/tags/lan-english/"/>
    
      <category term="web-scraping" scheme="http://yoursite.com/tags/web-scraping/"/>
    
  </entry>
  
  <entry>
    <title>Hello World</title>
    <link href="http://yoursite.com/2019/07/12/hello-world/"/>
    <id>http://yoursite.com/2019/07/12/hello-world/</id>
    <published>2019-07-12T14:45:42.001Z</published>
    <updated>2019-07-12T16:08:19.229Z</updated>
    
    <content type="html"><![CDATA[<p>Welcome to <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/" target="_blank" rel="noopener">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html" target="_blank" rel="noopener">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues" target="_blank" rel="noopener">GitHub</a>.</p><a id="more"></a><h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo new <span class="string">"My New Post"</span></span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/writing.html" target="_blank" rel="noopener">Writing</a></p><h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/server.html" target="_blank" rel="noopener">Server</a></p><h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/generating.html" target="_blank" rel="noopener">Generating</a></p><h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/deployment.html" target="_blank" rel="noopener">Deployment</a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Welcome to &lt;a href=&quot;https://hexo.io/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Hexo&lt;/a&gt;! This is your very first post. Check &lt;a href=&quot;https://hexo.io/docs/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;documentation&lt;/a&gt; for more info. If you get any problems when using Hexo, you can find the answer in &lt;a href=&quot;https://hexo.io/docs/troubleshooting.html&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;troubleshooting&lt;/a&gt; or you can ask me on &lt;a href=&quot;https://github.com/hexojs/hexo/issues&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;GitHub&lt;/a&gt;.&lt;/p&gt;
    
    </summary>
    
      <category term="life" scheme="http://yoursite.com/categories/life/"/>
    
    
  </entry>
  
</feed>
